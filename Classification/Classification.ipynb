{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6869ed6a",
   "metadata": {},
   "source": [
    "# HW 2 \n",
    "# Sai Raina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "596b9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b53a5b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'Grade.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00c71b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 4','Unnamed: 5'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58aaf70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HW</th>\n",
       "      <th>Midterm</th>\n",
       "      <th>Final</th>\n",
       "      <th>Pass/Fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>62</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>77</td>\n",
       "      <td>67</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>83</td>\n",
       "      <td>68</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91</td>\n",
       "      <td>73</td>\n",
       "      <td>78</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92</td>\n",
       "      <td>86</td>\n",
       "      <td>70</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HW  Midterm  Final Pass/Fail\n",
       "0  80       72     62         f\n",
       "1  63       77     67         f\n",
       "2  77       83     68         f\n",
       "3  91       73     78         f\n",
       "4  92       86     70         f"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61a78905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p    18\n",
       "f     9\n",
       "Name: Pass/Fail, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Pass/Fail'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06e99340",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "Y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22d7f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad7642da",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "733766f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9629629629629629"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b419731a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714285714285714"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict(X)\n",
    "\n",
    "f1_score(Y,pred,pos_label='p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fa4c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:,[\"Final\",\"HW\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8589695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8148148148148148\n",
      "F1 Score : 0.8648648648648649\n"
     ]
    }
   ],
   "source": [
    "# Final and HomeWork\n",
    "clf1 = LogisticRegression(random_state=0).fit(X, Y)\n",
    "print(\"Accuracy :\",clf1.score(X,Y))\n",
    "\n",
    "pred = clf1.predict(X)\n",
    "\n",
    "print(\"F1 Score :\",f1_score(Y,pred,pos_label='p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a07faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:,[\"Final\",\"Midterm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "456d4f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9259259259259259\n",
      "F1 Score : 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "# Midterm and Final\n",
    "clf2 = LogisticRegression(random_state=0).fit(X, Y)\n",
    "print(\"Accuracy :\",clf2.score(X,Y))\n",
    "\n",
    "pred = clf2.predict(X)\n",
    "\n",
    "print(\"F1 Score :\",f1_score(Y,pred,pos_label='p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3af931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:,[\"HW\",\"Midterm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "608e82ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HW and Midterm\n",
    "clf3 = LogisticRegression(random_state=0).fit(X, Y)\n",
    "clf3.score(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "688623ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.923076923076923"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf3.predict(X)\n",
    "\n",
    "f1_score(Y,pred,pos_label='p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "371cba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4e556a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Name</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HW</td>\n",
       "      <td>0.329293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Midterm</td>\n",
       "      <td>0.324590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Final</td>\n",
       "      <td>0.346117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Feature Name  Importance\n",
       "0           HW    0.329293\n",
       "1      Midterm    0.324590\n",
       "2        Final    0.346117"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    " \n",
    "forest = RandomForestClassifier(n_estimators=500,\n",
    "                                random_state=1)\n",
    "\n",
    "forest.fit(X, Y.values.ravel())\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "ft_imp = pd.DataFrame({'Feature Name':X.columns,'Importance':importances})\n",
    "ft_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b64ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:,[\"Final\",\"Midterm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef921d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9629629629629629"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=50,random_state=1,ccp_alpha=0.1)\n",
    "rf_clf.fit(X,Y)\n",
    "\n",
    "pred = rf_clf.predict(X)\n",
    "acc = rf_clf.score(X,Y)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6534793c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8,  1],\n",
       "       [ 0, 18]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4d97910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972972972972973"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y,pred,pos_label='p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "945a244f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           f       1.00      0.78      0.88         9\n",
      "           p       0.90      1.00      0.95        18\n",
      "\n",
      "    accuracy                           0.93        27\n",
      "   macro avg       0.95      0.89      0.91        27\n",
      "weighted avg       0.93      0.93      0.92        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b685c459",
   "metadata": {},
   "source": [
    "# The best model is the one that uses the features Midterm and Final scores to predict if the student will pass or fail.\n",
    "\n",
    "## This is based on the fact that it achieves the highest accuracy. To combat the slight imabalance in the dataset we can look at the f1-score which takes into consideration both precision and recall. The model which uses these features also has the highest f1-score.\n",
    "\n",
    "## I have used two models logistic regression and random forest classifier. Both perform similarly infact since the dataset is simple and small logistic regression does better and does not overfit. While random forest is slightly tending towards overfitting.\n",
    "\n",
    "### Logistic Regression --> \n",
    "    Accuracy : 0.9259259259259259\n",
    "    F1 Score : 0.9444444444444444\n",
    "    \n",
    "### Random Forest --> \n",
    "    Accuracy : 0.9629629629629629\n",
    "    F1 Score : 0.972972972972973"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
